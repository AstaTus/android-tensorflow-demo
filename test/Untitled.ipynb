{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93968385 0.9896217  0.9616751  0.68680006 0.07886846 0.4305005\n",
      " 0.9183656  0.7730132  0.62878704 0.3344889  0.56687486 0.4117625\n",
      " 0.5650344  0.12031923 0.09840573 0.464987   0.86380607 0.102442\n",
      " 0.23139091 0.3762166  0.27650204 0.3888789  0.84083223 0.42027384\n",
      " 0.27575442 0.6575207  0.38278362 0.4779308  0.15500216 0.4310156\n",
      " 0.2633422  0.43123662 0.11365478 0.28683946 0.49343982 0.3795285\n",
      " 0.22041772 0.07697375 0.0399555  0.19681448 0.23960389 0.357386\n",
      " 0.43576878 0.7253703  0.5653928  0.99783885 0.7957634  0.81034476\n",
      " 0.45282257 0.46583778 0.83823144 0.71966684 0.13230294 0.15562522\n",
      " 0.7127498  0.86957514 0.7554782  0.53165245 0.99644333 0.41528058\n",
      " 0.70166504 0.04656548 0.46585074 0.3672172  0.26923957 0.8590426\n",
      " 0.10150695 0.18594135 0.92588043 0.632805   0.75621265 0.01684418\n",
      " 0.0705372  0.47522134 0.02648669 0.22911292 0.8232609  0.8740721\n",
      " 0.54682285 0.07965519 0.5537542  0.06357151 0.54820585 0.9086952\n",
      " 0.6015897  0.6435244  0.8266881  0.02259161 0.62883705 0.02916237\n",
      " 0.39936742 0.3752001  0.26529753 0.6503826  0.03128073 0.02601514\n",
      " 0.7899683  0.91835827 0.9506936  0.4642519 ]\n",
      "[0.29396838 0.29896218 0.29616752 0.26868    0.20788684 0.24305005\n",
      " 0.29183656 0.2773013  0.26287872 0.2334489  0.2566875  0.24117625\n",
      " 0.25650343 0.21203193 0.20984058 0.2464987  0.28638062 0.21024421\n",
      " 0.22313909 0.23762167 0.22765021 0.23888789 0.28408322 0.24202739\n",
      " 0.22757545 0.26575208 0.23827836 0.24779308 0.21550022 0.24310157\n",
      " 0.22633423 0.24312367 0.21136548 0.22868395 0.24934399 0.23795286\n",
      " 0.22204177 0.20769738 0.20399556 0.21968146 0.2239604  0.2357386\n",
      " 0.24357688 0.27253702 0.2565393  0.2997839  0.27957633 0.28103447\n",
      " 0.24528226 0.24658379 0.28382313 0.2719667  0.2132303  0.21556252\n",
      " 0.27127498 0.2869575  0.27554783 0.25316525 0.29964435 0.24152806\n",
      " 0.27016652 0.20465656 0.24658507 0.23672172 0.22692396 0.28590426\n",
      " 0.2101507  0.21859413 0.29258806 0.2632805  0.27562127 0.20168442\n",
      " 0.20705372 0.24752215 0.20264867 0.2229113  0.2823261  0.28740722\n",
      " 0.2546823  0.20796552 0.25537542 0.20635715 0.2548206  0.29086953\n",
      " 0.26015896 0.26435244 0.28266883 0.20225917 0.26288372 0.20291623\n",
      " 0.23993674 0.23752001 0.22652976 0.26503825 0.20312807 0.20260152\n",
      " 0.27899683 0.29183584 0.29506937 0.2464252 ]\n",
      "------------------------------------------------------\n",
      "before the train, the W is -3.902292, the b is 0.014486\n",
      "------------------------------------------------------\n",
      "after epoch 0, the loss is 5.729103\n",
      "the W is -3.902292, the b is 0.014486\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 10, the loss is 0.199653\n",
      "the W is -1.411853, the b is 0.971225\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 20, the loss is 0.047463\n",
      "the W is -0.637139, the b is 0.576029\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 30, the loss is 0.011283\n",
      "the W is -0.259409, the b is 0.383342\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 40, the loss is 0.002682\n",
      "the W is -0.075238, the b is 0.289393\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 50, the loss is 0.000638\n",
      "the W is 0.014558, the b is 0.243585\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 60, the loss is 0.000152\n",
      "the W is 0.058341, the b is 0.221251\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 70, the loss is 0.000036\n",
      "the W is 0.079688, the b is 0.210361\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 80, the loss is 0.000009\n",
      "the W is 0.090096, the b is 0.205052\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 90, the loss is 0.000002\n",
      "the W is 0.095171, the b is 0.202463\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 100, the loss is 0.000000\n",
      "the W is 0.097646, the b is 0.201201\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 110, the loss is 0.000000\n",
      "the W is 0.098852, the b is 0.200586\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 120, the loss is 0.000000\n",
      "the W is 0.099440, the b is 0.200286\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 130, the loss is 0.000000\n",
      "the W is 0.099727, the b is 0.200139\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 140, the loss is 0.000000\n",
      "the W is 0.099867, the b is 0.200068\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 150, the loss is 0.000000\n",
      "the W is 0.099935, the b is 0.200033\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 160, the loss is 0.000000\n",
      "the W is 0.099968, the b is 0.200016\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 170, the loss is 0.000000\n",
      "the W is 0.099985, the b is 0.200008\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 180, the loss is 0.000000\n",
      "the W is 0.099992, the b is 0.200004\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 190, the loss is 0.000000\n",
      "the W is 0.099996, the b is 0.200002\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 200, the loss is 0.000000\n",
      "the W is 0.099998, the b is 0.200001\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 210, the loss is 0.000000\n",
      "the W is 0.099999, the b is 0.200000\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 220, the loss is 0.000000\n",
      "the W is 0.100000, the b is 0.200000\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 230, the loss is 0.000000\n",
      "the W is 0.100000, the b is 0.200000\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 240, the loss is 0.000000\n",
      "the W is 0.100000, the b is 0.200000\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 250, the loss is 0.000000\n",
      "the W is 0.100000, the b is 0.200000\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 260, the loss is 0.000000\n",
      "the W is 0.100000, the b is 0.200000\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 270, the loss is 0.000000\n",
      "the W is 0.100000, the b is 0.200000\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 280, the loss is 0.000000\n",
      "the W is 0.100000, the b is 0.200000\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "after epoch 290, the loss is 0.000000\n",
      "the W is 0.100000, the b is 0.200000\n",
      "save the model\n",
      "------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from model/my-model-290\n",
      "[0.09999995]\n",
      "[0.20000003]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def train_model():\n",
    "\n",
    "    # prepare the data\n",
    "    x_data = np.random.rand(100).astype(np.float32)\n",
    "    print(x_data)\n",
    "    y_data = x_data * 0.1 + 0.2\n",
    "    print(y_data)\n",
    "\n",
    "    # define the weights\n",
    "    W = tf.Variable(tf.random_uniform([1], -20.0, 20.0), dtype=tf.float32, name='w')\n",
    "    b = tf.Variable(tf.random_uniform([1], -10.0, 10.0), dtype=tf.float32, name='b')\n",
    "    y = W * x_data + b\n",
    "\n",
    "    # define the loss\n",
    "    loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # save model\n",
    "    saver = tf.train.Saver(max_to_keep=4)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print(\"------------------------------------------------------\")\n",
    "        print(\"before the train, the W is %6f, the b is %6f\" % (sess.run(W), sess.run(b)))\n",
    "\n",
    "        for epoch in range(300):\n",
    "            if epoch % 10 == 0:\n",
    "                print (\"------------------------------------------------------\")\n",
    "                print (\"after epoch %d, the loss is %6f\" % (epoch, sess.run(loss)))\n",
    "                print (\"the W is %f, the b is %f\" % (sess.run(W), sess.run(b)))\n",
    "                saver.save(sess, \"model/my-model\", global_step=epoch)\n",
    "                print (\"save the model\")\n",
    "            sess.run(train_step)\n",
    "        print (\"------------------------------------------------------\")\n",
    "\n",
    "def load_model():\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.import_meta_graph('model/my-model-290.meta')\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(\"model/\"))\n",
    "        print(sess.run('w:0'))\n",
    "        print(sess.run('b:0'))\n",
    "\n",
    "train_model()\n",
    "load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
